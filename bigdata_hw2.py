# -*- coding: utf-8 -*-
"""bigdata_hw2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/197faFqVs9DDihtP8r6gid0ASLw9wnW7t
"""

# install pyspark
!apt-get -y install openjdk-8-jre-headless
!pip install pyspark

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

"""**Q1**

> Find the maximal delays (you should consider both ArrDelay and DepDelay) for each month of 2007.
"""

from pyspark.sql import SparkSession

spark = SparkSession.builder\
        .master("local")\
        .appName("Colab")\
        .config('spark.ui.port', '4050')\
        .getOrCreate()

spark

df = spark.read.csv("/content/gdrive/MyDrive/bigdata_hw2/2007.csv", header=True, inferSchema=True)

df.printSchema()
df.show(5)

from pyspark.sql.functions import *

months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
for i in range(1, 13):
  print(months[i - 1] + ': ')
  print('DepDelay')
  df_month = df.filter(df.Month == i)
  df_month_DepDelay = df_month.filter("DepDelay != 'NA'")
  df_month_DepDelay = df_month_DepDelay.withColumn("DepDelay", df_month_DepDelay["DepDelay"].cast('int'))
  df_month_DepDelay.select(["DepDelay"]).orderBy(desc("DepDelay")).show(5)

  print('ArrDelay')
  df_month_ArrDelay = df_month.filter("ArrDelay != 'NA'")
  df_month_ArrDelay = df_month_ArrDelay.withColumn("ArrDelay", df_month_ArrDelay["ArrDelay"].cast('int'))
  df_month_ArrDelay.select(["ArrDelay"]).orderBy(desc("ArrDelay")).show(5)

"""**Q2**

> How many flights were delayed caused by security between 2000 ~ 2005? Please
show the counting for each year.


"""

files = ['2000.csv', '2001.csv', '2002.csv', '2003.csv', '2004.csv', '2005.csv']
total_SecurityDelay_count = 0
for file in files:
  fp = "/content/gdrive/MyDrive/bigdata_hw2/" + file
  df_SecurityDelay = spark.read.csv(fp, header=True, inferSchema=True)
  df_SecurityDelay.na.fill(0)
  df_SecurityDelay = df_SecurityDelay.withColumn("SecurityDelay", df_SecurityDelay["SecurityDelay"].cast('int'))
  df_SecurityDelay = df_SecurityDelay.filter("SecurityDelay > 0")

  tmp = df_SecurityDelay.count()
  total_SecurityDelay_count += tmp
  print(file[0:4] + ' has ' + str(tmp) + ' SecurityDelay.')
  if tmp != 0:
    df_SecurityDelay.select(["Year", "Month", "SecurityDelay"]).orderBy(desc("SecurityDelay")).show(5)

print("there are " + str(total_SecurityDelay_count) + " SecurityDelays between 2000 - 2005.")

"""**Q3**
> List Top 5 airports which occur delays most and least in 2008. (Please show the IATA airport code)
"""

fp = "/content/gdrive/MyDrive/bigdata_hw2/2008.csv"
df = spark.read.csv(fp, header=True, inferSchema=True)

df_DepDelay = df.select(["Origin", "DepDelay"])
df_ArrDelay = df.select(["Dest", "ArrDelay"])

# clear na
df_DepDelay.na.fill(0)
df_ArrDelay.na.fill(0)

df_DepDelay = df_DepDelay.filter("DepDelay > 0")
df_ArrDelay = df_ArrDelay.filter("ArrDelay > 0")

origin_delays = df_DepDelay.withColumn("IATA", df_DepDelay["Origin"])
print("most 5 origin delays")
top_origin = origin_delays.groupBy("IATA").count().orderBy(desc("count")).show(5)
print("least 5 origin delays")
least_origin = origin_delays.groupBy("IATA").count().orderBy("count").show(5)

dest_delays = df_ArrDelay.withColumn("IATA", df_ArrDelay["Dest"])
print("most 5 dest delays")
top_dest = dest_delays.groupBy("IATA").count().orderBy(desc("count")).show(5)
print("least 5 dest delays")
least_dest = dest_delays.groupBy("IATA").count().orderBy("count").show(5)

total_delays = origin_delays.union(dest_delays)
print("most 5 total delays")
top_total = total_delays.groupBy("IATA").count().orderBy(desc("count")).show(5)
print("least 5 total delays")
least_total = total_delays.groupBy("IATA").count().orderBy("count").show(5)